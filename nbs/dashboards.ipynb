{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dashboards\n",
    "\n",
    "> Supplies dashboards to investigate datasets and training results. Dashboards are defined as classes, to show the dashboard use the .show() function on an dashboard instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Union\n",
    "\n",
    "from bokeh.plotting import show, output_notebook\n",
    "from bokeh.models.widgets import DataTable, TableColumn, HTMLTemplateFormatter\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "import pandas as pd\n",
    "\n",
    "from icevision_dashboard.utils import *\n",
    "from icevision_dashboard.components import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = icedata.fridge.load_data()\n",
    "test_class_map = icedata.fridge.class_map()\n",
    "test_parser = icedata.fridge.parser(test_data_dir, test_class_map)\n",
    "test_train_records, test_valid_records = test_parser.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetOverview:\n",
    "    def __init__(self, records=None, data=None, class_map=None, height=500, width=1500):\n",
    "        \"\"\"If records is None no gallery will be generated. If the data is generated with aggregate_record_data and class map is used the class map needs to be provided as well.\"\"\"\n",
    "        if records is None and data is None:\n",
    "            raise ValueError(\"Either records or data needs to be given.\")\n",
    "        self.records = records\n",
    "        self.class_map = class_map\n",
    "        if data is None:\n",
    "            self.data = pd.DataFrame(aggregate_record_data(records, class_map))\n",
    "        else:\n",
    "            self.data = data\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "    def _generate_dataset_tab(self):\n",
    "        overview_table = table_from_dataframe(self.data, width=self.width, height=self.height)\n",
    "        return pn.Column(overview_table)\n",
    "        \n",
    "    def _generate_image_tab(self):\n",
    "        overview_table = table_from_dataframe(calculate_image_stats(self.data), width=self.width, height=50)\n",
    "        if self.records is None:\n",
    "            img_gallery = None\n",
    "        else:\n",
    "            img_gallery = gallery(self.records, self.class_map, height=self.height-20)\n",
    "        return pn.Column(pn.Row(overview_table, align=\"center\"), pn.Row(img_gallery, align=\"center\"))\n",
    "        \n",
    "    def _generate_class_tab(self):\n",
    "        overview_table = table_from_dataframe(calculate_class_stats(self.data), height=150)\n",
    "        mixing_matrix_df, mapping = calculate_mixing_matrix(self.data, mixing_col=\"filepath\", mixing_objects=\"label\")\n",
    "        plot_height = min(self.height-150, int(self.width/2))\n",
    "        mixing_histogram = histogram_2d(mixing_matrix_df, \"row_name\", \"col_name\", \"values\", height=plot_height, width=plot_height)\n",
    "        stacked_annotations_per_image_hist = annotations_per_image_stacked_hist(self.data, height=plot_height, width=plot_height)\n",
    "        return pn.Column(pn.Row(overview_table, align=\"center\"), pn.Row(mixing_histogram, stacked_annotations_per_image_hist, align=\"start\"), align=\"center\")\n",
    "        \n",
    "    def show(self):\n",
    "        dataset_tab = self._generate_dataset_tab()\n",
    "        image_tab = self._generate_image_tab()\n",
    "        class_tab = self._generate_class_tab()\n",
    "        \n",
    "        return pn.Tabs((\"Dataset overview\", dataset_tab), (\"Image stats\", image_tab), (\"Class stats\", class_tab), width=self.width, align=\"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dso = DatasetOverview(test_valid_records, class_map=test_class_map, height=500)\n",
    "dso.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dso = DatasetOverview(data=aggregate_record_data(test_valid_records, test_class_map), class_map=test_class_map, height=700, width=500)\n",
    "dso.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiDatasetOverview:\n",
    "    def __init__(self, datasets, height=500, width=1500):\n",
    "        self._datasets = datasets\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        \n",
    "    def create_datasets_overview(self):\n",
    "        dataset_stats_list = []\n",
    "        for dataset in self._datasets:\n",
    "            dataset_stats = calculate_dataset_stats(dataset)\n",
    "            dataset_stats[\"classes\"] = \", \".join([str(entry) for entry in dataset_stats[\"classes\"]])\n",
    "            dataset_stats_list.append(dataset_stats)\n",
    "        dataset_stats_df = pd.DataFrame(dataset_stats_list)\n",
    "        \n",
    "        template = \"\"\"<span href=\"#\" data-toggle=\"tooltip\" title=\"<%= value %>\"><%= value %></span>\"\"\"\n",
    "        table = pnw.DataFrame(dataset_stats_df, formatters={\"classes\": HTMLTemplateFormatter(template=template)}, selection=[0], width=self.width, height=int(self.height*0.3))\n",
    "        return table\n",
    "    \n",
    "    def show(self):\n",
    "        if len(self._datasets) == 0:\n",
    "            return None\n",
    "        del_button = pnw.Button(name=\"Delete\", width=self.width)\n",
    "        datasets_overview = self.create_datasets_overview()\n",
    "        dataset_overview = DatasetOverview(data=self._datasets[datasets_overview.selection[0]], width=self.width, height=int(self.height*0.7)).show()\n",
    "        gui = pn.Column(del_button, datasets_overview, dataset_overview)\n",
    "        \n",
    "        def update_on_table_selection(selection):\n",
    "            nonlocal dataset_overview\n",
    "            old_active = dataset_overview.active\n",
    "            dataset_overview = DatasetOverview(data=self._datasets[datasets_overview.selection[0]], width=self.width, height=int(self.height*0.7)).show()\n",
    "            dataset_overview.active = old_active\n",
    "            gui[-1] = dataset_overview\n",
    "        datasets_overview.param.watch(update_on_table_selection, 'selection')\n",
    "        \n",
    "        def delete_entry(clicks):\n",
    "            nonlocal datasets_overview\n",
    "            nonlocal dataset_overview\n",
    "            nonlocal gui\n",
    "            self._datasets = [dataset for index, dataset in enumerate(self._datasets) if index not in datasets_overview.selection]\n",
    "            datasets_overview = self.create_datasets_overview()\n",
    "            datasets_overview.param.watch(update_on_table_selection, 'selection')\n",
    "            gui[1] = datasets_overview\n",
    "            \n",
    "            if len(self._datasets) == 0:\n",
    "                gui[-1] = None\n",
    "            else:\n",
    "                old_active = dataset_overview.active\n",
    "                dataset_overview = DatasetOverview(data=self._datasets[datasets_overview.selection[0]], width=self.width, height=int(self.height*0.7)).show()\n",
    "                dataset_overview.active = old_active\n",
    "                gui[-1] = dataset_overview\n",
    "        del_button.on_click(delete_entry)\n",
    "        \n",
    "        return gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = aggregate_record_data(test_valid_records, test_class_map)\n",
    "mdo = MultiDatasetOverview([test_dataset.iloc[:10], test_dataset.iloc[:50], test_dataset.iloc[:60], test_dataset], width=500, height=500)\n",
    "mdo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdo_empty = MultiDatasetOverview([])\n",
    "assert mdo_empty.show() is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetFilter:\n",
    "    \"\"\"Creates a gallery with filter options to select subsets of the data. If the export_varialbe is set to a variable, that is a list a dict with the current selection (pd.Dataframe (key: data) and list of records (key: records)) will be append to the list.\"\"\"\n",
    "    def __init__(self, records, class_map=None, export_variable: Union[list, None] = None, height=500, width=500):\n",
    "        self.records = records\n",
    "        self.class_map = class_map\n",
    "        self.export_variable = export_variable\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "    \n",
    "        self.inner_width = int(0.97*width)\n",
    "        self.data = aggregate_record_data(records, class_map)\n",
    "            \n",
    "        self.filters = []\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_mask_from_range(values, selections):\n",
    "        return (values >= selections[0]) & (values < selections[1])\n",
    "    \n",
    "    @staticmethod\n",
    "    def export_filter(filtered_records, filtered_data):\n",
    "        \"Filter function applied to the output of get_filtered_records_and_data inside the show function. This is to allow for modification of the exported data.\"\n",
    "        return {\"data\": filtered_data, \"records\": filtered_records}\n",
    "    \n",
    "    def show(self):\n",
    "        \"\"\"Creates a gallery with filter options to select subsets of the data. If the export_varialbe is set to a variable, that is a list a dict with the current selection (pd.Dataframe (key: data) and list of records (key: records)) will be append to the list.\"\"\"\n",
    "        # generate bbox filters\n",
    "        options = self.data[\"label\"].unique()\n",
    "        options.sort()\n",
    "        bbox_class_filter = pnw.MultiSelect(name=\"Class\", options=options.tolist(), value=options.tolist())\n",
    "        bbox_num_annotations_filter = generate_range_filter(self.data[\"num_annotations\"], \"Num. Annotations\", steps=self.data[\"num_annotations\"].max()+3, width=int(self.width/2))\n",
    "        bbox_area_filter = generate_range_filter(self.data[\"area\"], \"Area\", steps=10, width=int(self.width/2))\n",
    "        bbox_width_filter = generate_range_filter(self.data[\"bbox_width\"], \"Bbox width\", steps=10, width=int(self.width/2))\n",
    "        bbox_height_filter = generate_range_filter(self.data[\"bbox_height\"], \"Bbbox height\", steps=10, width=int(self.width/2))\n",
    "        bbox_ratio_filter = generate_range_filter(self.data[\"bbox_ratio\"], \"Ratio\", steps=10, width=int(self.width/2))\n",
    "        annotation_filters = pn.Row(pn.Column(bbox_class_filter, bbox_num_annotations_filter, bbox_area_filter, width=int(self.width/2)), pn.Column(bbox_width_filter, bbox_height_filter, bbox_ratio_filter, width=int(self.width/2)))\n",
    "\n",
    "        # generate image filters\n",
    "        file_creation_modification_time_filter = generate_creation_modification_time_filter(self.data, width=int(self.width/2))\n",
    "        file_width_filter = generate_range_filter(self.data[\"width\"], \"Width\", steps=10, width=int(self.width/2))\n",
    "        file_height_filter = generate_range_filter(self.data[\"height\"], \"Height\", steps=10, width=int(self.width/2))\n",
    "        file_filters = pn.Row(pn.Column(file_creation_modification_time_filter, width=int(self.width/2)), pn.Column(file_width_filter, file_height_filter, width=int(self.width/2)))\n",
    "\n",
    "        filters = pn.Tabs((\"File filters\", file_filters), (\"Annotation filters\", annotation_filters), (\"Gallery\", None), width=self.width, active=1)\n",
    "\n",
    "        def get_filtered_records_and_data():\n",
    "            filtered_data = self.data[\n",
    "                self.data[\"label\"].isin(bbox_class_filter.value)\n",
    "                & self._get_mask_from_range(self.data[\"num_annotations\"], bbox_num_annotations_filter[0].value)\n",
    "                & self._get_mask_from_range(self.data[\"area\"], bbox_area_filter[0].value)\n",
    "                & self._get_mask_from_range(self.data[\"bbox_width\"], bbox_width_filter[0].value)\n",
    "                & self._get_mask_from_range(self.data[\"bbox_height\"], bbox_height_filter[0].value)\n",
    "                & self._get_mask_from_range(self.data[\"bbox_ratio\"], bbox_ratio_filter[0].value)\n",
    "                & self._get_mask_from_range(self.data[\"creation_date\"], file_creation_modification_time_filter[1].value)\n",
    "                & self._get_mask_from_range(self.data[\"modification_date\"], file_creation_modification_time_filter[2].value)\n",
    "                & self._get_mask_from_range(self.data[\"width\"], file_width_filter[0].value)\n",
    "                & self._get_mask_from_range(self.data[\"height\"], file_height_filter[0].value)\n",
    "            ]\n",
    "            filtered_records = [self.records[i] for i in filtered_data[\"record_index\"].unique()]\n",
    "            return filtered_records, filtered_data\n",
    "\n",
    "        @pn.depends(\n",
    "            bbox_class_filter.param.value, bbox_num_annotations_filter[0].param.value_throttled, bbox_area_filter[0].param.value_throttled, \n",
    "            bbox_width_filter[0].param.value_throttled, bbox_height_filter[0].param.value_throttled, bbox_ratio_filter[0].param.value_throttled,\n",
    "            file_creation_modification_time_filter[1].param.value_throttled, file_creation_modification_time_filter[2].param.value_throttled, \n",
    "            file_width_filter[0].param.value_throttled, file_height_filter[0].param.value_throttled\n",
    "        )\n",
    "        def _gallery(\n",
    "            classes_selection, num_annotation_selection, area_selection, width_selection, height_selection, ratio_selection, \n",
    "            image_creation_date_selection, image_modification_date_selection, image_with_selection, image_height_selection\n",
    "        ):\n",
    "            filtered_records, filtered_data = get_filtered_records_and_data()\n",
    "\n",
    "            # update filter histograms\n",
    "            bbox_num_annotations_filter[1] = histogram(self.data.groupby(\"id\").count()[\"width\"], bins=20, height=100, width=int(self.width/2), range=(self.data.groupby(\"id\").count()[\"width\"].min(), self.data.groupby(\"id\").count()[\"width\"].max()), remove_tools=True)\n",
    "            bbox_area_filter[1] = histogram(filtered_data[\"area\"], bins=20, height=100, width=int(self.width/2), range=(self.data[\"area\"].min(), self.data[\"area\"].max()), remove_tools=True)\n",
    "            bbox_width_filter[1] = histogram(filtered_data[\"bbox_width\"], bins=20, height=100, width=int(self.width/2), range=(self.data[\"bbox_width\"].min(), self.data[\"bbox_width\"].max()), remove_tools=True)\n",
    "            bbox_height_filter[1] = histogram(filtered_data[\"bbox_height\"], bins=20, height=100, width=int(self.width/2), range=(self.data[\"bbox_height\"].min(), self.data[\"bbox_height\"].max()), remove_tools=True)\n",
    "            bbox_ratio_filter[1] = histogram(filtered_data[\"bbox_ratio\"], bins=20, height=100, width=int(self.width/2), range=(self.data[\"bbox_ratio\"].min(), self.data[\"bbox_ratio\"].max()), remove_tools=True)\n",
    "\n",
    "            if len(filtered_records) == 0:\n",
    "                return None\n",
    "            else:\n",
    "                return gallery(filtered_records, width=self.width, height=self.height)\n",
    "\n",
    "        if self.export_variable is not None:\n",
    "            def export(event):\n",
    "                filtered_records, filtered_data = get_filtered_records_and_data()\n",
    "                export_result = self.export_filter(filtered_records, filtered_data)\n",
    "                self.export_variable.append(export_result)\n",
    "\n",
    "            export_button = pnw.Button(name=\"Export\")           \n",
    "            export_button.on_click(export)\n",
    "            filters[2] = (\"Gallery\", _gallery)\n",
    "            return pn.Column(filters, export_button, align=\"center\")\n",
    "        else:\n",
    "            return pn.Column(filters, align=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_var = []\n",
    "ds_filter = DatasetFilter(test_valid_records, test_class_map, export_variable=dump_var, width=700, height=500).show()\n",
    "# trigger click event to test if record is added to dump_var\n",
    "ds_filter[-1].clicks += 1\n",
    "assert len(dump_var) == 1\n",
    "assert len(dump_var[0][\"records\"]) == len(test_valid_records)\n",
    "ds_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObservableList:\n",
    "    def __init__(self, observable_list):\n",
    "        self._observable_list = observable_list\n",
    "        self._observer = []\n",
    "    \n",
    "    def register_callback(self, callback):\n",
    "        self._observer.append(callback)\n",
    "    \n",
    "    def _trigger_observer(self):\n",
    "        for observer in self._observer:\n",
    "            observer(self._observable_list)\n",
    "    \n",
    "    @property\n",
    "    def observable_list(self):\n",
    "        return self._observable_list\n",
    "    \n",
    "    @observable_list.setter\n",
    "    def observable_list(self, value):\n",
    "        self._observable_list = value\n",
    "        self._trigger_observer()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for item in self._observable_list:\n",
    "            yield item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._observable_list)\n",
    "    \n",
    "    def append(self, item):\n",
    "        self._observable_list.append(item)\n",
    "        self._trigger_observer()\n",
    "        \n",
    "    def remove(self, item):\n",
    "        self._observable_list.remove(item)\n",
    "        self._trigger_observer()\n",
    "        \n",
    "    def insert(self, index, item):\n",
    "        self._observable_list.insert(index, item)\n",
    "        self._trigger_observer()\n",
    "    \n",
    "    def pop(self, index=-1):\n",
    "        poped_item = self._observable_list.pop(index)\n",
    "        self._trigger_observer()\n",
    "        return poped_item\n",
    "    \n",
    "    def extend(self, iterable):\n",
    "        self._observable_list.extend(iterable)\n",
    "        self._trigger_observer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetFilterThatOnlyExportsStats(DatasetFilter):\n",
    "    @staticmethod\n",
    "    def export_filter(filtered_records, filtered_data):\n",
    "        return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_var = []\n",
    "dstoes_filter = DatasetFilterThatOnlyExportsStats(test_valid_records, test_class_map, export_variable=dump_var).show()\n",
    "# trigger click event to test if record is added to dump_var\n",
    "dstoes_filter[-1].clicks += 1\n",
    "assert len(dump_var) == 1\n",
    "assert isinstance(dump_var[0], pd.DataFrame)\n",
    "dstoes_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetCreator:\n",
    "    def __init__(self, records, class_map=None, height=500, width=1000):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.records = records\n",
    "        self.class_map = class_map\n",
    "        self.data = aggregate_record_data(records, class_map)\n",
    "        self._datasets = ObservableList([])\n",
    "        self._datasets.register_callback(self.update_datasets_overview)\n",
    "        self._filter = DatasetFilterThatOnlyExportsStats(records, class_map, export_variable=self._datasets, width=self.width, height=self.height).show()\n",
    "        self._datasets_overview = MultiDatasetOverview(self._datasets.observable_list, width=self.width, height=self.height)\n",
    "        self._gui = pn.Tabs((\"Filter datasets\", self._filter), (\"Inspect datasets\", self._datasets_overview.show()))\n",
    "        \n",
    "    def update_datasets_overview(self, datasets):\n",
    "        self._gui[1] = (\"Inspect datasets\", self._datasets_overview.show())\n",
    "        \n",
    "    def show(self):\n",
    "        return self._gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = DatasetCreator(test_valid_records, test_class_map)\n",
    "dsc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dahboard for comparing train and val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TrainValRecordsComparison:\n",
    "    \"\"\"\n",
    "    Dashboard to compare the generated train and val records, to ensure the don't diverge to much from each other.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_records, val_records, class_map=None):\n",
    "        self.train_records = train_records\n",
    "        self.val_records = val_records\n",
    "        self.class_map = class_map\n",
    "        self.data = self._aggregate_data()\n",
    "    \n",
    "    def _aggregate_data(self):\n",
    "        \"\"\"Aggregates data from train and val records into a dataframe\"\"\"\n",
    "        train_data = aggregate_record_data(self.train_records)\n",
    "        val_data = aggregate_record_data(self.val_records)\n",
    "        train_data[\"type\"] = \"train\"\n",
    "        val_data[\"type\"] = \"val\"\n",
    "        full_data = pd.concat([val_data, train_data])\n",
    "        # convert the label column to the corrosponding names if a class_map is present and shift the previous labels to a label_num column\n",
    "        # use the label column for here on generically\n",
    "        if self.class_map is not None:\n",
    "            full_data[\"label_num\"] = full_data[\"label\"]\n",
    "            full_data[\"label\"] = full_data[\"label\"].apply(self.class_map.get_id)\n",
    "        return full_data\n",
    "    \n",
    "    def _collect_stat(self):\n",
    "        \"\"\"Calculates stats on the aggregated data for the two datasets sets and returns them as a dataframe.\"\"\"\n",
    "        train_stats = {}\n",
    "        val_stats = {}\n",
    "        deviation_stats = {}\n",
    "        # collect stats\n",
    "        grouping = self.data.groupby(\"type\")\n",
    "        train_group = grouping.get_group(\"train\")\n",
    "        val_group = grouping.get_group(\"val\")\n",
    "        train_label_fractions = train_group.value_counts(\"label\") / train_group.shape[0]\n",
    "        val_label_fractions = val_group.value_counts(\"label\") / val_group.shape[0]\n",
    "        for key, value in val_label_fractions.items():\n",
    "            val_stats[\"label_fraction_\"+key] = value\n",
    "        for key, value in train_label_fractions.items():\n",
    "            train_stats[\"label_fraction_\"+key] = value\n",
    "        val_stats[\"area_min\"] = val_group[\"area\"].min()\n",
    "        val_stats[\"area_max\"] = val_group[\"area\"].max()\n",
    "        val_stats[\"area_avg\"] = val_group[\"area\"].mean()\n",
    "        val_stats[\"area_std\"] = val_group[\"area\"].std()\n",
    "        train_stats[\"area_min\"] = train_group[\"area\"].min()\n",
    "        train_stats[\"area_max\"] = train_group[\"area\"].max()\n",
    "        train_stats[\"area_avg\"] = train_group[\"area\"].mean()\n",
    "        train_stats[\"area_std\"] = train_group[\"area\"].std()\n",
    "        \n",
    "        # calculated deviations dict\n",
    "        for key, value in train_stats.items():\n",
    "            deviation_stats[key] = 1-val_stats[key]/value\n",
    "        # convert the dicts to dfs\n",
    "        train_stats = pd.DataFrame(train_stats, index=[\"train\"])\n",
    "        val_stats = pd.DataFrame(val_stats, index=[\"val\"])\n",
    "        deviation_stats = pd.DataFrame(deviation_stats, index=[\"deviation (1-val/train)\"])\n",
    "        data = pd.concat([train_stats, val_stats, deviation_stats]).T\n",
    "        data = data.round(2)\n",
    "        data = data.reset_index()\n",
    "        data[\"index\"] = data[\"index\"].apply(lambda x: x.replace(\"_\", \" \").title())\n",
    "        return data\n",
    "    \n",
    "    def comparison_table(self, width=600, height=600):\n",
    "        \"\"\"Generates a table that compares stats between train and val datasets.\"\"\"\n",
    "        data = self._collect_stat()\n",
    "        source = ColumnDataSource(data)\n",
    "        \n",
    "        columns = [TableColumn(field=filed, title=filed.replace(\"_\", \" \").title()) for filed in data.columns]\n",
    "        data_table = DataTable(source=source, columns=columns, width=width, height=height)\n",
    "        return data_table\n",
    "    \n",
    "    def area_histogram(self, width=500, height=500):\n",
    "        \"\"\"Generates area histogram for the train and val dataset.\"\"\"\n",
    "        return comparison_histogram_with_gui([group[1] for group in self.data.groupby(\"type\")], hist_func=area_histogram, width=width, height=height)\n",
    "    \n",
    "    def show(self):\n",
    "        table = self.comparison_table(width=600, height=250)\n",
    "        area_histogram = self.area_histogram(width=600, height=500)\n",
    "        \n",
    "        return pn.Column(table, area_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvr_comp = TrainValRecordsComparison(test_train_records, test_valid_records, test_class_map)\n",
    "tvr_comp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
