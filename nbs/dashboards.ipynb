{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dashboards\n",
    "\n",
    "> Supplies dashboards to investigate datasets and training results. Dashboards are defined as classes, to show the dashboard use the .show() function on an dashboard instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Union\n",
    "\n",
    "from bokeh.plotting import show, output_notebook\n",
    "from bokeh.models.widgets import DataTable, TableColumn, HTMLTemplateFormatter\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "import pandas as pd\n",
    "\n",
    "from icevision_dashboard.utils import *\n",
    "from icevision_dashboard.components import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = icedata.fridge.load_data()\n",
    "test_class_map = icedata.fridge.class_map()\n",
    "test_parser = icedata.fridge.parser(test_data_dir, test_class_map)\n",
    "test_train_records, test_valid_records = test_parser.parse()\n",
    "test_record_dataset = RecordDataset(test_valid_records, test_class_map)\n",
    "test_record_dataset_no_class_map = RecordDataset(test_valid_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RecordDatasetOverview:\n",
    "    def __init__(self, record_dataset, height=500, width=1500):\n",
    "        \"\"\"If records is None no gallery will be generated. If the data is generated with aggregate_record_data and class map is used the class map needs to be provided as well.\"\"\"\n",
    "        self.record_dataset = record_dataset\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "    def _generate_dataset_tab(self):\n",
    "        overview_table = table_from_dataframe(self.record_dataset.data, width=self.width, height=self.height)\n",
    "        return pn.Column(overview_table)\n",
    "        \n",
    "    def _generate_image_tab(self):\n",
    "        overview_table = table_from_dataframe(self.record_dataset.image_stats, width=self.width, height=50)\n",
    "        if self.record_dataset.records is None:\n",
    "            img_gallery = None\n",
    "        else:\n",
    "            img_gallery = gallery(self.record_dataset.records, self.record_dataset.class_map, height=self.height-20)\n",
    "        return pn.Column(pn.Row(overview_table, align=\"center\"), pn.Row(img_gallery, align=\"center\"))\n",
    "        \n",
    "    def _generate_class_tab(self):\n",
    "        overview_table = table_from_dataframe(self.record_dataset.class_stats, height=150)\n",
    "        mixing_matrix_df, mapping = calculate_mixing_matrix(self.record_dataset.data, mixing_col=\"filepath\", mixing_objects=\"label\")\n",
    "        plot_height = min(self.height-150, int(self.width/2))\n",
    "        mixing_histogram = histogram_2d(mixing_matrix_df, \"row_name\", \"col_name\", \"values\", height=plot_height, width=plot_height)\n",
    "        stacked_annotations_per_image_hist = annotations_per_image_stacked_hist(self.record_dataset.data, height=plot_height, width=plot_height)\n",
    "        return pn.Column(pn.Row(overview_table, align=\"center\"), pn.Row(mixing_histogram, stacked_annotations_per_image_hist, align=\"start\"), align=\"center\")\n",
    "        \n",
    "    def show(self):\n",
    "        dataset_tab = self._generate_dataset_tab()\n",
    "        image_tab = self._generate_image_tab()\n",
    "        class_tab = self._generate_class_tab()\n",
    "        \n",
    "        return pn.Tabs((\"Dataset overview\", dataset_tab), (\"Image stats\", image_tab), (\"Class stats\", class_tab), width=self.width, align=\"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dso = RecordDatasetOverview(test_record_dataset, height=500)\n",
    "dso.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dso = RecordDatasetOverview(test_record_dataset_no_class_map, height=700, width=500)\n",
    "dso.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiDatasetOverview:\n",
    "    def __init__(self, datasets, height=500, width=1500):\n",
    "        self._datasets = datasets\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "    \n",
    "    def show(self):\n",
    "        if len(self._datasets) == 0:\n",
    "            return None\n",
    "        del_button = pnw.Button(name=\"Delete\", width=self.width)\n",
    "        datasets_overview = create_datasets_overview(self._datasets, width=self.width, height=int(0.3*self.height))\n",
    "        dataset_overview = RecordDatasetOverview(self._datasets[datasets_overview.selection[0]], width=self.width, height=int(self.height*0.7)).show()\n",
    "        gui = pn.Column(del_button, datasets_overview, dataset_overview)\n",
    "        \n",
    "        def update_on_table_selection(selection):\n",
    "            nonlocal dataset_overview\n",
    "            old_active = dataset_overview.active\n",
    "            dataset_overview = DatasetOverview(data=self._datasets[datasets_overview.selection[0]], width=self.width, height=int(self.height*0.7)).show()\n",
    "            dataset_overview.active = old_active\n",
    "            gui[-1] = dataset_overview\n",
    "        datasets_overview.param.watch(update_on_table_selection, 'selection')\n",
    "        \n",
    "        def delete_entry(clicks):\n",
    "            nonlocal datasets_overview\n",
    "            nonlocal dataset_overview\n",
    "            nonlocal gui\n",
    "            self._datasets = [dataset for index, dataset in enumerate(self._datasets) if index not in datasets_overview.selection]\n",
    "            datasets_overview = create_datasets_overview(self._datasets, width=self.width, height=int(0.3*self.height))\n",
    "            datasets_overview.param.watch(update_on_table_selection, 'selection')\n",
    "            gui[1] = datasets_overview\n",
    "            \n",
    "            if len(self._datasets) == 0:\n",
    "                gui[-1] = None\n",
    "            else:\n",
    "                old_active = dataset_overview.active\n",
    "                dataset_overview = DatasetOverview(data=self._datasets[datasets_overview.selection[0]], width=self.width, height=int(self.height*0.7)).show()\n",
    "                dataset_overview.active = old_active\n",
    "                gui[-1] = dataset_overview\n",
    "        del_button.on_click(delete_entry)\n",
    "        \n",
    "        return gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdo = MultiDatasetOverview([test_record_dataset, test_record_dataset_no_class_map], width=800, height=500)\n",
    "mdo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdo_empty = MultiDatasetOverview([])\n",
    "assert mdo_empty.show() is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetFilter:\n",
    "    \"\"\"Creates a gallery with filter options to select subsets of the data. If the export_varialbe is set to a variable, that is a list a dict with the current selection (pd.Dataframe (key: data) and list of records (key: records)) will be append to the list.\"\"\"\n",
    "    def __init__(self, record_dataset, export_variable: Union[list, None] = None, height=500, width=500):\n",
    "        self.record_dataset = record_dataset\n",
    "        self.export_variable = export_variable\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "    \n",
    "        self.filters = []\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_mask_from_range(values, selections):\n",
    "        return (values >= selections[0]) & (values < selections[1])\n",
    "    \n",
    "    @staticmethod\n",
    "    def export_filter(filtered_records, filtered_data):\n",
    "        \"Filter function applied to the output of get_filtered_records_and_data inside the show function. This is to allow for modification of the exported data.\"\n",
    "        return {\"data\": filtered_data, \"records\": filtered_records}\n",
    "    \n",
    "    def show(self):\n",
    "        \"\"\"Creates a gallery with filter options to select subsets of the data. If the export_varialbe is set to a variable, that is a list a dict with the current selection (pd.Dataframe (key: data) and list of records (key: records)) will be append to the list.\"\"\"\n",
    "        # generate bbox filters\n",
    "        options = self.record_dataset.data[\"label\"].unique()\n",
    "        options.sort()\n",
    "        bbox_class_filter = pnw.MultiSelect(name=\"Class\", options=options.tolist(), value=options.tolist())\n",
    "        bbox_num_annotations_filter = generate_range_filter(self.record_dataset.data[\"num_annotations\"], \"Num. Annotations\", steps=self.record_dataset.data[\"num_annotations\"].max()+3, width=int(self.width/2))\n",
    "        bbox_area_filter = generate_range_filter(self.record_dataset.data[\"area\"], \"Area\", steps=50, width=int(self.width/2))\n",
    "        bbox_width_filter = generate_range_filter(self.record_dataset.data[\"bbox_width\"], \"Bbox width\", steps=50, width=int(self.width/2))\n",
    "        bbox_height_filter = generate_range_filter(self.record_dataset.data[\"bbox_height\"], \"Bbbox height\", steps=50, width=int(self.width/2))\n",
    "        bbox_ratio_filter = generate_range_filter(self.record_dataset.data[\"bbox_ratio\"], \"Ratio\", steps=50, width=int(self.width/2))\n",
    "        annotation_filters = pn.Row(pn.Column(bbox_class_filter, bbox_num_annotations_filter, bbox_area_filter, width=int(self.width/2)), pn.Column(bbox_width_filter, bbox_height_filter, bbox_ratio_filter, width=int(self.width/2)))\n",
    "\n",
    "        # generate image filters\n",
    "        file_creation_modification_time_filter = generate_creation_modification_time_filter(self.record_dataset.data, width=int(self.width/2))\n",
    "        file_width_filter = generate_range_filter(self.record_dataset.data[\"width\"], \"Width\", steps=50, width=int(self.width/2))\n",
    "        file_height_filter = generate_range_filter(self.record_dataset.data[\"height\"], \"Height\", steps=50, width=int(self.width/2))\n",
    "        file_filters = pn.Row(pn.Column(file_creation_modification_time_filter, width=int(self.width/2)), pn.Column(file_width_filter, file_height_filter, width=int(self.width/2)))\n",
    "\n",
    "        filters = pn.Tabs((\"File filters\", file_filters), (\"Annotation filters\", annotation_filters), (\"Gallery\", None), width=self.width, active=1)\n",
    "        \n",
    "        def get_filtered_records_and_data():\n",
    "            filtered_data = self.record_dataset.data[\n",
    "                self.record_dataset.data[\"label\"].isin(bbox_class_filter.value)\n",
    "                & self._get_mask_from_range(self.record_dataset.data[\"num_annotations\"], bbox_num_annotations_filter[0].value)\n",
    "                & self._get_mask_from_range(self.record_dataset.data[\"area\"], bbox_area_filter[0].value)\n",
    "                & self._get_mask_from_range(self.record_dataset.data[\"bbox_width\"], bbox_width_filter[0].value)\n",
    "                & self._get_mask_from_range(self.record_dataset.data[\"bbox_height\"], bbox_height_filter[0].value)\n",
    "                & self._get_mask_from_range(self.record_dataset.data[\"bbox_ratio\"], bbox_ratio_filter[0].value)\n",
    "                & self._get_mask_from_range(self.record_dataset.data[\"creation_date\"], file_creation_modification_time_filter[1].value)\n",
    "                & self._get_mask_from_range(self.record_dataset.data[\"modification_date\"], file_creation_modification_time_filter[2].value)\n",
    "                & self._get_mask_from_range(self.record_dataset.data[\"width\"], file_width_filter[0].value)\n",
    "                & self._get_mask_from_range(self.record_dataset.data[\"height\"], file_height_filter[0].value)\n",
    "            ]\n",
    "            filtered_records = [self.record_dataset.records[i] for i in filtered_data[\"record_index\"].unique()]\n",
    "            return filtered_records, filtered_data\n",
    "\n",
    "        @pn.depends(\n",
    "            bbox_class_filter.param.value, bbox_num_annotations_filter[0].param.value_throttled, bbox_area_filter[0].param.value_throttled, \n",
    "            bbox_width_filter[0].param.value_throttled, bbox_height_filter[0].param.value_throttled, bbox_ratio_filter[0].param.value_throttled,\n",
    "            file_creation_modification_time_filter[1].param.value_throttled, file_creation_modification_time_filter[2].param.value_throttled, \n",
    "            file_width_filter[0].param.value_throttled, file_height_filter[0].param.value_throttled\n",
    "        )\n",
    "        def _gallery(\n",
    "            classes_selection, num_annotation_selection, area_selection, width_selection, height_selection, ratio_selection, \n",
    "            image_creation_date_selection, image_modification_date_selection, image_with_selection, image_height_selection\n",
    "        ):\n",
    "            filtered_records, filtered_data = get_filtered_records_and_data()\n",
    "\n",
    "            # update filter histograms\n",
    "            bbox_num_annotations_filter[1] = histogram(\n",
    "                self.record_dataset.data.groupby(\"id\").count()[\"width\"], bins=20, height=100, width=int(self.width/2), \n",
    "                range=(self.record_dataset.data.groupby(\"id\").count()[\"width\"].min(), self.record_dataset.data.groupby(\"id\").count()[\"width\"].max()), remove_tools=True)\n",
    "            \n",
    "            bbox_area_filter[1] = histogram(\n",
    "                filtered_data[\"area\"], bins=20, height=100, width=int(self.width/2), \n",
    "                range=(self.record_dataset.data[\"area\"].min(), self.record_dataset.data[\"area\"].max()), remove_tools=True)\n",
    "            \n",
    "            bbox_width_filter[1] = histogram(\n",
    "                filtered_data[\"bbox_width\"], bins=20, height=100, width=int(self.width/2), \n",
    "                range=(self.record_dataset.data[\"bbox_width\"].min(), self.record_dataset.data[\"bbox_width\"].max()), remove_tools=True)\n",
    "            \n",
    "            bbox_height_filter[1] = histogram(\n",
    "                filtered_data[\"bbox_height\"], bins=20, height=100, width=int(self.width/2), \n",
    "                range=(self.record_dataset.data[\"bbox_height\"].min(), self.record_dataset.data[\"bbox_height\"].max()), remove_tools=True)\n",
    "            \n",
    "            bbox_ratio_filter[1] = histogram(\n",
    "                filtered_data[\"bbox_ratio\"], bins=20, height=100, width=int(self.width/2), \n",
    "                range=(self.record_dataset.data[\"bbox_ratio\"].min(), self.record_dataset.data[\"bbox_ratio\"].max()), remove_tools=True)\n",
    "\n",
    "            if len(filtered_records) == 0:\n",
    "                return None\n",
    "            else:\n",
    "                return gallery(filtered_records, width=self.width, height=self.height)\n",
    "\n",
    "        if self.export_variable is not None:\n",
    "            def export(event):\n",
    "                filtered_records, filtered_data = get_filtered_records_and_data()\n",
    "                export_result = self.export_filter(filtered_records, filtered_data)\n",
    "                self.export_variable.append(export_result)\n",
    "\n",
    "            export_button = pnw.Button(name=\"Export\")           \n",
    "            export_button.on_click(export)\n",
    "            filters[2] = (\"Gallery\", _gallery)\n",
    "            return pn.Column(filters, export_button, align=\"center\")\n",
    "        else:\n",
    "            return pn.Column(filters, align=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_var = []\n",
    "ds_filter = DatasetFilter(test_record_dataset, export_variable=dump_var, width=1000, height=500).show()\n",
    "# trigger click event to test if record is added to dump_var\n",
    "ds_filter[-1].clicks += 1\n",
    "assert len(dump_var) == 1\n",
    "assert len(dump_var[0][\"records\"]) == len(test_valid_records)\n",
    "ds_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetFilterThatOnlyExportsStats(DatasetFilter):\n",
    "    @staticmethod\n",
    "    def export_filter(filtered_records, filtered_data):\n",
    "        return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_var = []\n",
    "dstoes_filter = DatasetFilterThatOnlyExportsStats(test_record_dataset, export_variable=dump_var, height=400).show()\n",
    "# trigger click event to test if record is added to dump_var\n",
    "dstoes_filter[-1].clicks += 1\n",
    "assert len(dump_var) == 1\n",
    "assert isinstance(dump_var[0], pd.DataFrame)\n",
    "dstoes_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetCreator:\n",
    "    def __init__(self, record_dataset, class_map=None, height=500, width=1000):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.record_dataset = record_dataset\n",
    "        self._datasets = ObservableList([])\n",
    "        self._datasets.register_callback(self.update_datasets_overview)\n",
    "        self._filter = DatasetFilterThatOnlyExportsStats(self.record_dataset, export_variable=self._datasets, width=self.width, height=self.height).show()\n",
    "        self._datasets_overview = MultiDatasetOverview(self._datasets.observable_list, width=self.width, height=self.height)\n",
    "        print(self._datasets_overview._datasets)\n",
    "        self._gui = pn.Tabs((\"Filter datasets\", self._filter), (\"Inspect datasets\", self._datasets_overview.show()), (\"Export datasets\", self.export_gui()))\n",
    "        \n",
    "    @staticmethod\n",
    "    def export_datasets(datasets):\n",
    "        pass\n",
    "        \n",
    "    def export_gui(self):\n",
    "        export_path = pnw.TextInput(name=\"Export path\", value=\"./datasets\")\n",
    "        export_button = pnw.Button(name=\"Export\")\n",
    "        \n",
    "        datasets_overview = create_datasets_overview(self._datasets)\n",
    "#         def create_datasets_overview(datasets, width=500, height=100):\n",
    "#             \"Creates an overview table for a list of datasets were each datasets is a dataframe.\"\n",
    "#             dataset_stats_list = []\n",
    "#             for dataset in datasets:\n",
    "#                 dataset_stats = calculate_dataset_stats(dataset)\n",
    "#                 dataset_stats[\"classes\"] = \", \".join([str(entry) for entry in dataset_stats[\"classes\"]])\n",
    "#                 dataset_stats_list.append(dataset_stats)\n",
    "#             dataset_stats_df = pd.DataFrame(dataset_stats_list)\n",
    "\n",
    "#             template = \"\"\"<span href=\"#\" data-toggle=\"tooltip\" title=\"<%= value %>\"><%= value %></span>\"\"\"\n",
    "#             table = pnw.DataFrame(dataset_stats_df, formatters={\"classes\": HTMLTemplateFormatter(template=template)}, selection=[0], width=width, height=height)\n",
    "#             return table\n",
    "        \n",
    "        \n",
    "        return pn.Column(export_path, datasets_overview, export_button)\n",
    "        \n",
    "    def update_datasets_overview(self, datasets):\n",
    "        print(self._datasets_overview.show())\n",
    "#         self._gui[1] = (\"Inspect datasets\", self._datasets_overview.show())\n",
    "#         self._gui[-1] = (\"Export datasets\", self.export_gui())\n",
    "        pass\n",
    "        \n",
    "    def show(self):\n",
    "        return self._gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = DatasetCreator(test_record_dataset, test_class_map)\n",
    "dsc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc._datasets.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets_overview([test_record_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
