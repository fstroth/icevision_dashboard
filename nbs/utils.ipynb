{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> Supplies basic utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import datetime\n",
    "from typing import Union\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, TableColumn, DataTable, LinearColorMapper, ColorBar\n",
    "from bokeh.models.widgets import HTMLTemplateFormatter\n",
    "from bokeh.palettes import Viridis\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "import pandas as pd\n",
    "\n",
    "import icevision.parsers as parsers\n",
    "from icevision.data.data_splitter import RandomSplitter\n",
    "from icevision.core.bbox import BBox\n",
    "\n",
    "from icevision.visualize.draw_data import draw_record, draw_pred\n",
    "from icevision.core.class_map import ClassMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = icedata.fridge.load_data()\n",
    "test_class_map = icedata.fridge.class_map()\n",
    "test_parser = icedata.fridge.parser(test_data_dir, test_class_map)\n",
    "test_train_records, test_valid_records = test_parser.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObservableList:\n",
    "    def __init__(self, observable_list):\n",
    "        self._observable_list = observable_list\n",
    "        self._observer = []\n",
    "    \n",
    "    def register_callback(self, callback):\n",
    "        self._observer.append(callback)\n",
    "    \n",
    "    def _trigger_observer(self):\n",
    "        for observer in self._observer:\n",
    "            observer(self._observable_list)\n",
    "    \n",
    "    @property\n",
    "    def observable_list(self):\n",
    "        return self._observable_list\n",
    "    \n",
    "    @observable_list.setter\n",
    "    def observable_list(self, value):\n",
    "        self._observable_list = value\n",
    "        self._trigger_observer()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self._observable_list.__repr__()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for item in self._observable_list:\n",
    "            yield item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._observable_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self._observable_list[idx]\n",
    "    \n",
    "    def __setitem__(self, idx, value):\n",
    "        self._observable_list[idx] = value\n",
    "        self._trigger_observer()\n",
    "    \n",
    "    def append(self, item):\n",
    "        self._observable_list.append(item)\n",
    "        self._trigger_observer()\n",
    "        \n",
    "    def remove(self, item):\n",
    "        self._observable_list.remove(item)\n",
    "        self._trigger_observer()\n",
    "        \n",
    "    def insert(self, index, item):\n",
    "        self._observable_list.insert(index, item)\n",
    "        self._trigger_observer()\n",
    "    \n",
    "    def pop(self, index=-1):\n",
    "        poped_item = self._observable_list.pop(index)\n",
    "        self._trigger_observer()\n",
    "        return poped_item\n",
    "    \n",
    "    def extend(self, iterable):\n",
    "        self._observable_list.extend(iterable)\n",
    "        self._trigger_observer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_list = ObservableList([])\n",
    "call_register = []\n",
    "obs_list.register_callback(lambda x: call_register.append(x))\n",
    "obs_list.observable_list = [1]\n",
    "assert call_register[-1] == obs_list.observable_list\n",
    "obs_list.observable_list.append(2)\n",
    "assert call_register[-1] == obs_list.observable_list\n",
    "\n",
    "obs_list.observable_list.pop()\n",
    "assert call_register[-1] == obs_list.observable_list\n",
    "\n",
    "obs_list.observable_list.extend([3,4,5])\n",
    "assert call_register[-1] == obs_list.observable_list\n",
    "\n",
    "obs_list.observable_list.insert(2, 4)\n",
    "assert call_register[-1] == obs_list.observable_list\n",
    "\n",
    "obs_list.observable_list.remove(4)\n",
    "assert call_register[-1] == obs_list.observable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RecordDataframeParser(parsers.FasterRCNN, parsers.FilepathMixin, parsers.SizeMixin):\n",
    "    def __init__(self, record_dataframe):\n",
    "        self.record_dataframe = record_dataframe\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for group in self.record_dataframe.groupby(\"filepath\"):\n",
    "            yield group[1]\n",
    "    \n",
    "    def imageid(self, o):\n",
    "        return o.iloc[0][\"id\"]\n",
    "    \n",
    "    def filepath(self, o):\n",
    "        return o.iloc[0][\"filepath\"]\n",
    "    \n",
    "    def image_width_height(self, o):\n",
    "        width, height = o.iloc[0][\"width\"], o.iloc[0][\"height\"]\n",
    "        return (width, height)\n",
    "    \n",
    "    def bboxes(self, o):\n",
    "        return [BBox(annot[1][\"bbox_xmin\"], annot[1][\"bbox_ymin\"], annot[1][\"bbox_xmax\"], annot[1][\"bbox_ymax\"]) for annot in o.iterrows()]\n",
    "    \n",
    "    def labels(self, o):\n",
    "        return [annot[1][\"label_num\"] for annot in o.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_class_map_from_record_df(record_df):\n",
    "    sorted_labels = record_df[\"label\"].unique()[np.argsort(record_df[\"label_num\"].unique())].tolist()\n",
    "    sorted_label_nums = sorted(record_df[\"label_num\"].unique())\n",
    "    label_map = {key: value for key, value in zip(sorted_label_nums, sorted_labels)}\n",
    "    return ClassMap([label_map[i] if i in label_map.keys() else \"unknown_\"+str(i) for i in range(max(sorted_label_nums))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RecordDataset:\n",
    "    def __init__(self, records: Union[list, ObservableList, str], class_map=None, name=None, description=None):\n",
    "        if isinstance(records, str):\n",
    "            self.load_from_file(records)\n",
    "        else:\n",
    "            self.records = records if isinstance(records, ObservableList) else ObservableList(records)\n",
    "            self.class_map = class_map\n",
    "            self._name = \"dataset\" if name is None else name\n",
    "            self._description = \"\" if description is None else description\n",
    "        \n",
    "        self.records.register_callback(self.reset_infert_data)\n",
    "        \n",
    "        self.__variables = []\n",
    "        self._callbacks = []\n",
    "        self.register_variable(\"_data\")\n",
    "        self.register_variable(\"_dataset_stats\")\n",
    "        self.register_variable(\"_class_stats\")\n",
    "        self.register_variable(\"_image_stats\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        base_string = \"\"\n",
    "        for key, value in self.dataset_stats.items():\n",
    "            base_string += str(key) + \": \" + str(value) + \" | \"\n",
    "        base_string = base_string[:-2]\n",
    "        return base_string\n",
    "    \n",
    "    def register_callback(self, callback):\n",
    "        self._callbacks.append(callback)\n",
    "        \n",
    "    def trigger_callbacks(self):\n",
    "        for callback in self._callbacks:\n",
    "            callback()\n",
    "    \n",
    "    def set_variable_if_is_none_and_return_it(self, variable, value_func):\n",
    "        if variable is None:\n",
    "            variable = value_func()\n",
    "        return variable\n",
    "        \n",
    "    def register_variable(self, variable_name, value=None):\n",
    "        setattr(self, variable_name, None)\n",
    "        self.__variables.append(variable_name)\n",
    "        \n",
    "    def reset_infert_data(self, update):\n",
    "        for variable_name in self.__variables:\n",
    "            setattr(self, variable_name, None)\n",
    "        \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, value):\n",
    "        self._name = value\n",
    "        self.reset_infert_data(None)\n",
    "    \n",
    "    @property\n",
    "    def description(self):\n",
    "        return self._description\n",
    "        \n",
    "    @description.setter\n",
    "    def description(self, value):\n",
    "        self._description = value\n",
    "        self.reset_infert_data(None)\n",
    "        \n",
    "    @classmethod\n",
    "    def load_from_record_dataframe(cls, record_data_df: pd.DataFrame, class_map=None, name=None, description=None):\n",
    "        records = RecordDataframeParser(record_data_df).parse(RandomSplitter([1]))[0]\n",
    "        if class_map is None:\n",
    "            class_map = create_class_map_from_record_df(record_data_df)\n",
    "        return cls(records, class_map=class_map, name=name, description=description)\n",
    "\n",
    "    def load_from_file(self, path):\n",
    "        data = json.load(open(path))\n",
    "        df = pd.DataFrame(data[\"data\"])\n",
    "        records = RecordDataframeParser(df).parse(RandomSplitter([1]))[0]\n",
    "        \n",
    "        self.records = ObservableList(records)\n",
    "        self.class_map = ClassMap(data[\"class_map\"])\n",
    "        self._name = data[\"name\"]\n",
    "        self._description = data[\"description\"]\n",
    "    \n",
    "    def save(self, save_path):\n",
    "        if not os.path.isdir(save_path):\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "        save_name = \"dataset\" if self.name == \"\" else self.name\n",
    "        if not os.path.isfile(os.path.join(save_path, save_name+\".json\")):\n",
    "            save_name = save_name+\".json\"\n",
    "        else:\n",
    "            counter = 1\n",
    "            while True:\n",
    "                save_name = save_name+\"(\"+str(counter)+\").json\"\n",
    "                if os.path.isfile(os.path.join(save_path, save_name)):\n",
    "                    counter += 1\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        class_map = self.class_map if self.class_map is not None else create_class_map_from_record_df(df)\n",
    "        save_data = {\"name\": self.name, \"description\": self.description, \"data\": self.data.to_dict(), \"class_map\": class_map.id2class}\n",
    "        \n",
    "        json.dump(save_data, open(os.path.join(save_path, save_name), \"w\"), default=str)\n",
    "    \n",
    "    def calculate_record_data(self):\n",
    "        \"\"\"Aggregates stats from a list of records and returns a pandas dataframe with the aggregated stats. The creation time is not necessarily the real creation time. \n",
    "        This depends on the OS, for more information see: https://docs.python.org/3/library/os.html#os.stat_result.\"\"\"\n",
    "        data = []\n",
    "        for index,record in enumerate(self.records):\n",
    "            for label, bbox in zip(record[\"labels\"], record[\"bboxes\"]):\n",
    "                file_stats = record[\"filepath\"].stat()\n",
    "                bbox_widht = bbox.xmax - bbox.xmin\n",
    "                bbox_height = bbox.ymax - bbox.ymin\n",
    "                area = bbox_widht * bbox_height\n",
    "                area_normalized = area / (record[\"width\"] * record[\"height\"])\n",
    "                bbox_ratio = bbox_widht / bbox_height\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"id\": record[\"imageid\"], \"width\": record[\"width\"], \"height\": record[\"height\"], \"label\": label, \n",
    "                        \"bbox_xmin\": bbox.xmin, \"bbox_xmax\": bbox.xmax, \"bbox_ymin\": bbox.ymin, \"bbox_ymax\": bbox.ymax, \"area\": area, \n",
    "                        \"area_normalized\": area_normalized, \"bbox_ratio\": bbox_ratio, \"record_index\": index, \"bbox_width\": bbox_widht, \n",
    "                        \"bbox_height\": bbox_height, \"filepath\": str(record[\"filepath\"]), \"creation_date\": datetime.datetime.fromtimestamp(file_stats.st_ctime), \n",
    "                        \"modification_date\": datetime.datetime.fromtimestamp(file_stats.st_mtime), \"num_annotations\": len(record[\"bboxes\"])\n",
    "                    }\n",
    "                )\n",
    "        data = pd.DataFrame(data)\n",
    "        data[\"label_num\"] = data[\"label\"]\n",
    "        if self.class_map is not None:\n",
    "            data[\"label\"] = data[\"label\"].apply(self.class_map.get_id)\n",
    "        return data\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self.set_variable_if_is_none_and_return_it(self._data, self.calculate_record_data)\n",
    "    \n",
    "    def calculate_dataset_stats(self):\n",
    "        stats_dict = {}\n",
    "        stats_dict[\"no_imgs\"] = self.data[\"filepath\"].nunique()\n",
    "        stats_dict[\"no_classes\"] = self.data[\"label\"].nunique()\n",
    "        stats_dict[\"classes\"] = list(self.data[\"label\"].unique())\n",
    "        stats_dict[\"area_min\"] = self.data[\"area\"].min()\n",
    "        stats_dict[\"area_max\"] = self.data[\"area\"].max()\n",
    "        stats_dict[\"num_annotations_min\"] = self.data[\"num_annotations\"].min()\n",
    "        stats_dict[\"num_annotations_max\"] = self.data[\"num_annotations\"].max()\n",
    "        stats_dict[\"name\"] = self._name\n",
    "        stats_dict[\"description\"] = self._description\n",
    "        return stats_dict\n",
    "    \n",
    "    @property\n",
    "    def dataset_stats(self):\n",
    "        return self.set_variable_if_is_none_and_return_it(self._dataset_stats, self.calculate_dataset_stats)\n",
    "    \n",
    "    def calculate_class_stats(self):\n",
    "        \"\"\"Creates a dataframe containing stats about the object classes.\"\"\"\n",
    "        stats_dict = {}\n",
    "        label_group = self.data.groupby(\"label\")\n",
    "        for label, group in label_group:\n",
    "            label_stats = {}\n",
    "            label_stats[\"imgs\"] = group[\"filepath\"].nunique()\n",
    "            label_stats[\"objects\"] = group.shape[0]\n",
    "            label_stats[\"objects_per_img\"] = label_stats[\"objects\"]/label_stats[\"imgs\"]\n",
    "            label_stats[\"frac_of_labels\"] = round(label_stats[\"objects\"]/self.data.shape[0], 2)\n",
    "            stats_dict[label] = label_stats\n",
    "        df = pd.DataFrame(stats_dict).T\n",
    "        df = df.rename_axis('Class').reset_index()\n",
    "        return df\n",
    "    \n",
    "    @property\n",
    "    def class_stats(self):\n",
    "        return self.set_variable_if_is_none_and_return_it(self._class_stats, self.calculate_class_stats)\n",
    "    \n",
    "    def calculate_image_stats(self):\n",
    "        \"\"\"Creates a dataframe containing stats about the images.\"\"\"\n",
    "        stats_dict = {}\n",
    "        stats_dict[\"Num. imgs.\"] = self.data[\"filepath\"].nunique()\n",
    "        stats_dict[\"Min Num. Objects\"] = self.data[\"num_annotations\"].min()\n",
    "        stats_dict[\"Max Num. Objects\"] = self.data[\"num_annotations\"].max()\n",
    "        stats_dict[\"Avg. Objects/Img\"] = round(self.data[\"num_annotations\"].mean(),2)\n",
    "        df = pd.DataFrame.from_dict(stats_dict, orient=\"index\").T\n",
    "        return df\n",
    "    \n",
    "    @property\n",
    "    def image_stats(self):\n",
    "        return self.set_variable_if_is_none_and_return_it(self._image_stats, self.calculate_image_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_record_dataset = RecordDataset(test_valid_records, test_class_map)\n",
    "assert isinstance(test_record_dataset.data, pd.DataFrame)\n",
    "assert isinstance(test_record_dataset.dataset_stats, dict)\n",
    "assert isinstance(test_record_dataset.class_stats, pd.DataFrame)\n",
    "assert isinstance(test_record_dataset.image_stats, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_record_dataset.name = \"Test\"\n",
    "assert test_record_dataset.name == \"Test\"\n",
    "test_record_dataset.description = \"A short description\"\n",
    "assert test_record_dataset.description == \"A short description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_old_record_dataset_stats = test_record_dataset.dataset_stats\n",
    "test_record_dataset.records.observable_list = test_train_records\n",
    "test_new_record_dataset_stats = test_record_dataset.dataset_stats\n",
    "assert test_old_record_dataset_stats != test_new_record_dataset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_regenerated_record_dataset = RecordDataset.load_from_record_dataframe(test_record_dataset.data)\n",
    "assert len(test_regenerated_record_dataset.records) == len(test_record_dataset.records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"dump_dir\", ignore_errors=True)\n",
    "os.mkdir(\"dump_dir\")\n",
    "test_record_dataset.name = \"\"\n",
    "test_record_dataset.save(\"dump_dir\")\n",
    "test_record_dataset.save(\"dump_dir\")\n",
    "assert len(os.listdir(\"dump_dir\")) == 2\n",
    "assert os.path.isfile(\"dump_dir/dataset.json\")\n",
    "test_loaded_record_dataset = RecordDataset(\"dump_dir/dataset.json\")\n",
    "assert test_record_dataset.data.sort_values(\"area\").shape == test_loaded_record_dataset.data.sort_values(\"id\").shape\n",
    "shutil.rmtree(\"dump_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_mixing_matrix(data, mixing_col, mixing_objects, return_df=True):\n",
    "    \"\"\"Calculates mixing matrix for the mixing_objects column where they mix in the mixing_col. \n",
    "    By standard the object class mixing matrix over the images is calculated. \n",
    "    Returns the mixing matrix and the mapping between label and mixing matrix index.\n",
    "    If return_df is True (default) a dataframe (instead of the mixing matrix) will be returned that can be directly consumed by histogram_2d.\"\"\"\n",
    "    # map labels to the mixing matrix index\n",
    "    mapping = {i:j for j,i in enumerate(np.sort(data[mixing_objects].unique()))}\n",
    "    mixing_matrix = np.zeros([data[mixing_objects].nunique(), data[mixing_objects].nunique()])\n",
    "    mixing_groups = data.groupby(mixing_col)\n",
    "    # iterate over each individual element with the same mixing_col to calculate the mixing based on the mixing_objects\n",
    "    for group_key, group in mixing_groups:\n",
    "        # handel self mixing\n",
    "        for value, count in group[mixing_objects].value_counts().iteritems():\n",
    "            if count > 1:\n",
    "                mixing_matrix[mapping[value]] += 1\n",
    "        # handel mixing of different objects\n",
    "        permutations = np.array(np.meshgrid(group[mixing_objects].unique(), group[mixing_objects].unique())).T.reshape(-1,2)\n",
    "        for permutation in permutations:\n",
    "            # avoid double counting in the self mixing \n",
    "            if permutation[0] != permutation[1]:\n",
    "                mixing_matrix[mapping[permutation[0]], mapping[permutation[1]]] += 1\n",
    "    if return_df:\n",
    "        df_dict = {\"values\": [], \"col_name\": [], \"row_name\": []}\n",
    "        for row_name, row in zip(mapping, mixing_matrix):\n",
    "            df_dict[\"values\"] += row.tolist()\n",
    "            df_dict[\"row_name\"] += [row_name]*len(mapping)\n",
    "            df_dict[\"col_name\"] += mapping\n",
    "        return pd.DataFrame(df_dict), mapping\n",
    "    return mixing_matrix, mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only counts once if objects occure in the same image not multiplt times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test without class_map\n",
    "test_mixing_matrix_df, test_mixing_matrix_mapping = calculate_mixing_matrix(test_record_dataset.data, mixing_col=\"filepath\", mixing_objects=\"label\")\n",
    "# test class_map\n",
    "test_mixing_matrix_df, test_mixing_matrix_mapping = calculate_mixing_matrix(test_record_dataset.data, mixing_col=\"filepath\", mixing_objects=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mixing_matrix_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def convert_rgb_image_to_bokeh_rgb_image(img: np.ndarray):\n",
    "    \"\"\"Convertes a image in the form of a numpy array to an array that can be shown by bokeh.\"\"\"\n",
    "    img = np.flipud(img)\n",
    "    img = img.astype(np.uint8)\n",
    "    bokeh_img = np.empty((img.shape[0],img.shape[1]), dtype=np.uint32)\n",
    "    view = bokeh_img.view(dtype=np.uint8).reshape((img.shape[0],img.shape[1], 4))\n",
    "    view[:,:, 0] = img[:,:,0]\n",
    "    view[:,:, 1] = img[:,:,1]\n",
    "    view[:,:, 2] = img[:,:,2]\n",
    "    view[:,:, 3] = 255\n",
    "    return bokeh_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bokeh requries images to be in a hw format where each value is a 32bit integer where each of the 8bit sequences contains the rgb and alpha values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "img = np.random.randint(0, 256, [10,10,3], dtype=np.uint8)\n",
    "bokeh_img = convert_rgb_image_to_bokeh_rgb_image(img)\n",
    "assert bokeh_img.shape == (10,10)\n",
    "assert bokeh_img.dtype == np.uint32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def draw_record_with_bokeh(\n",
    "    record,\n",
    "    class_map=None,\n",
    "    display_label=True,\n",
    "    display_bbox=False,\n",
    "    display_mask=False,\n",
    "    display_keypoints=False,\n",
    "    return_figure=False,\n",
    "    width=None,\n",
    "    height=None\n",
    "):\n",
    "    \"\"\"Draws a record or returns a bokeh figure containing the image.\"\"\"\n",
    "    img = draw_record(\n",
    "            record=record,\n",
    "            class_map=class_map,\n",
    "            display_label=display_label,\n",
    "            display_bbox=display_bbox,\n",
    "            display_mask=display_mask,\n",
    "            display_keypoints=display_keypoints,\n",
    "        )\n",
    "\n",
    "    # create bokeh figure with the plot\n",
    "    bokeh_img = convert_rgb_image_to_bokeh_rgb_image(img)\n",
    "    \n",
    "    # make sure the aspect ratio of the image is retained, if only the width of hight is given\n",
    "    if width is None and height is not None:\n",
    "        plot_width = int(img.shape[1]/img.shape[0] * height)\n",
    "        plot_height = height\n",
    "    elif height is None and width is not None:\n",
    "        plot_width = width\n",
    "        plot_height = int(img.shape[0]/img.shape[1] * width)\n",
    "    else:\n",
    "        plot_width = img.shape[1] if width is None else width\n",
    "        plot_height = img.shape[0] if height is None else height\n",
    "    \n",
    "    p = figure(tools=\"reset, wheel_zoom, box_zoom, save, pan\", width=plot_width, height=plot_height, x_range=(0, img.shape[1]), y_range=(img.shape[0], 0), x_axis_location=\"above\")\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.image_rgba([bokeh_img], x=0, y=img.shape[0], dw=img.shape[1], dh=img.shape[0], level=\"image\")\n",
    "    if return_figure:\n",
    "        return p\n",
    "    else:\n",
    "        show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper around the `draw_record` function from icevision. The aspect ratio of the image will be preserved when only width or height is given (scaling the other accordingly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_record_with_bokeh(test_train_records[0], width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def barplot(counts, values, class_map=None, bar_type=\"horizontal\", width=500, height=500):\n",
    "    \"\"\"Creates a figure with a barplot, were the counts is the bar height and values are the labels for the bars.\"\"\"\n",
    "    if class_map is None:\n",
    "        values = [str(entry) for entry in values]\n",
    "    else:\n",
    "        values = [class_map.get_id(entry) for entry in values]\n",
    "    if bar_type == \"horizontal\":\n",
    "        p = figure(width=width, height=height, y_range=values)\n",
    "        p.hbar(y=values, left=0, right=counts, height=0.9)\n",
    "    elif bar_type == \"vertical\":\n",
    "        p = figure(width=width, height=height, x_range=values)\n",
    "        p.vbar(x=values, bottom=0, top=counts, width=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"hist_type has to be of 'horizontal' or 'vertical'\")\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test draw_histogram without a classmap\n",
    "p = barplot([10, 20], [1,2])\n",
    "pn.Row(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test draw_histogram without a classmap\n",
    "hist = [[1, 10], [2, 20]]\n",
    "cls_map = ClassMap([\"a\", \"b\"])\n",
    "p = barplot([10, 20], [1, 2], cls_map, bar_type=\"vertical\")\n",
    "pn.Row(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def histogram(values, bins=10, range=None, density=False, plot_figure=None, remove_tools=False, width=500, height=500):\n",
    "    \"Creates a histogram\"\n",
    "    if plot_figure is None:\n",
    "        p = figure(width=width, height=height)\n",
    "    else:\n",
    "        p = plot_figure\n",
    "    counts, edges = np.histogram(values, bins=bins, range=range, density=density)\n",
    "    p.quad(top=counts, bottom=0, left=edges[:-1], right=edges[1:])\n",
    "    if remove_tools:\n",
    "        p.toolbar.logo = None\n",
    "        p.toolbar_location = None\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(histogram([1,1,1,1,2,2,2,3,3,4], bins=4, range=(1,4), density=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(title=\"Test\")\n",
    "p = histogram([1,1,1,1,2,2,2,3,3,4], bins=4, plot_figure=p)\n",
    "pn.Row(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def histogram_2d(df, x, y, values, color_mapper=None, height=500, width=500):\n",
    "    if color_mapper is None:\n",
    "        color_mapper = LinearColorMapper(palette=Viridis[256], low=df[values].min(), high=df[values].max())\n",
    "    \n",
    "    # ensure the x and y column are in a categorical format\n",
    "    if df[x].dtype != str or df[y].dtype != str:\n",
    "        df = df.copy()\n",
    "        df[x] = df[x].astype(str)\n",
    "        df[y] = df[y].astype(str)\n",
    "    \n",
    "    p = figure(\n",
    "        title=\"Classes in image mixing matrix\", x_range=sorted(df[x].unique())[::-1], y_range=sorted(df[y].unique()), \n",
    "        x_axis_location=\"above\", tools=\"hover\", toolbar_location=None, tooltips=[('Mixing images: ', '@'+values)],\n",
    "        width=width, height=height\n",
    "    )\n",
    "\n",
    "    p.grid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_standoff = 0\n",
    "\n",
    "    p.rect(\n",
    "        x=x, y=y, width=1, height=1, source=df,\n",
    "        fill_color={'field': values, 'transform': color_mapper},\n",
    "        line_color=None\n",
    "    )\n",
    "\n",
    "    color_bar = ColorBar(\n",
    "        color_mapper=color_mapper, major_label_text_font_size=\"7px\",\n",
    "        #ticker=BasicTicker(desired_num_ticks=len(colors)),\n",
    "        label_standoff=6, border_line_color=None, location=(0, 0)\n",
    "    )\n",
    "    p.add_layout(color_bar, 'right')\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Column(histogram_2d(test_mixing_matrix_df, \"row_name\", \"col_name\", \"values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def time_arc_plot(start_date, end_date, plot_figure=None, width=500, height=300):\n",
    "    radius = (end_date-start_date)/2\n",
    "    x = start_date + radius\n",
    "    if plot_figure is None:\n",
    "        p = figure(x_axis_label=\"Date\", x_axis_type='datetime', y_range=(0, radius.max()), x_range=(start_date.min(), end_date.max()), width=width, height=height)\n",
    "        p.yaxis.major_tick_line_color = None\n",
    "        p.yaxis.minor_tick_line_color = None\n",
    "        p.yaxis.major_label_text_font_size = '0pt'\n",
    "        p.toolbar.logo = None\n",
    "        p.toolbar_location = None\n",
    "    else:\n",
    "        p = plot_figure\n",
    "    p.arc(x=x, y=0, radius=radius, start_angle=0, end_angle=np.pi)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_time_delta = pd.DataFrame([datetime.timedelta(days=np.random.randint(0, 50)) for _ in range(test_record_dataset.data.shape[0])], columns=[\"t_delta\"])\n",
    "pn.Row(time_arc_plot(test_record_dataset.data[\"creation_date\"], test_record_dataset.data[\"modification_date\"]+random_time_delta[\"t_delta\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def table_from_dataframe(dataframe, columns=None, width=500, height=200, index_position=None):\n",
    "    if columns is not None:\n",
    "        selection = dataframe[columns]\n",
    "    else:\n",
    "        selection = dataframe\n",
    "    source = ColumnDataSource(selection)\n",
    "    table_cols = [TableColumn(field=filed, title=filed.replace(\"_\", \" \").title()) for filed in selection.columns]\n",
    "    data_table = DataTable(source=source, columns=table_cols, width=width, height=height)\n",
    "    data_table.index_position = index_position\n",
    "    return data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(table_from_dataframe(test_record_dataset.data, width=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_datasets_overview(datasets, cols=None, width=500, height=100):\n",
    "    \"Creates an overview table for a list of record datasets. With cols the columns for the resulting table can be choosen.\"\n",
    "    dataset_stats_list = []\n",
    "    for dataset in datasets:\n",
    "        dataset_stats = dataset.dataset_stats\n",
    "        dataset_stats[\"classes\"] = \", \".join([str(entry) for entry in dataset_stats[\"classes\"]])\n",
    "        dataset_stats = dataset_stats if cols is None else {key: value for key, value in dataset_stats.items() if key in cols}\n",
    "        dataset_stats_list.append(dataset_stats)\n",
    "    dataset_stats_df = pd.DataFrame(dataset_stats_list)\n",
    "\n",
    "    template = \"\"\"<span href=\"#\" data-toggle=\"tooltip\" title=\"<%= value %>\"><%= value %></span>\"\"\"\n",
    "    table = pnw.DataFrame(dataset_stats_df, formatters={key: HTMLTemplateFormatter(template=template) for key in dataset_stats_df.columns}, selection=[0], width=width, height=height)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets_overview([test_record_dataset, test_record_dataset, test_record_dataset], cols=[\"no_imgs\", \"classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets_overview([test_record_dataset, test_record_dataset, test_record_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controll elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_range_filter(data, name, with_hist=True, steps=50, height=500, width=500):\n",
    "    \"Generates a range slider with a histogram (if with_hist is True) for a given pd.DataFrame and a column key.\"\n",
    "    val_min = data.min()\n",
    "    val_max = data.max()\n",
    "    # subtract and add a bit to the min and max value to ensure the whole range is captured\n",
    "    dist = val_max-val_min if val_max != val_min else 1\n",
    "    val_min = val_min-0.01*dist\n",
    "    val_max = val_max+0.01*dist\n",
    "    slider = pnw.RangeSlider(name=name, start=val_min, end=val_max, step=round(((val_max-val_min)/steps), 1), width=int(0.97*width))\n",
    "    if with_hist:\n",
    "        hist = histogram(data, bins=20, height=100, width=width, remove_tools=True)\n",
    "    else:\n",
    "        hist = None\n",
    "    range_filter = pn.Column(slider, hist, \"<br>\")\n",
    "    return range_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_range_filter(test_record_dataset.data[\"area\"], \"Area\", width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_min_and_max_dates(dates):\n",
    "    min_date = dates.min().to_pydatetime().replace(microsecond=0, second=0, minute=0, hour=0)\n",
    "    max_date = dates.max().to_pydatetime().replace(microsecond=0, second=0, minute=0, hour=0)\n",
    "    # make sure the min and max values are at least a day appart\n",
    "    if min_date == max_date:\n",
    "        max_date = max_date.replace(day=max_date.day+1)\n",
    "    return min_date, max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_creation_modification_time_filter(data, width=500, height=500):\n",
    "    \"\"\"Generates an arc plot with creation and modification time and two range sliders to select parts for the two.\"\"\"\n",
    "    plot = time_arc_plot(data[\"creation_date\"], data[\"modification_date\"], width=width)\n",
    "    min_creation_date, max_creation_date = get_min_and_max_dates(data[\"creation_date\"])\n",
    "    min_modification_date, max_modification_date = get_min_and_max_dates(data[\"modification_date\"])\n",
    "    min_date = min(min_creation_date, min_modification_date)\n",
    "    max_date = max(max_creation_date, max_modification_date)\n",
    "    creation_time_slider = pnw.DateRangeSlider(name=\"Creation Time\", start=min_date, end=max_date, width=width)\n",
    "    modification_time_slider = pnw.DateRangeSlider(name=\"Modification Time\", start=min_date, end=max_date, width=width)\n",
    "    return pn.Column(plot, creation_time_slider, modification_time_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_selection = test_record_dataset.data.copy()\n",
    "test_time_selection[\"modification_date\"] += random_time_delta[\"t_delta\"]\n",
    "generate_creation_modification_time_filter(test_time_selection, width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
